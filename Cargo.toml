[package]
name = "localgpt"
version = "0.1.0"
edition = "2021"
description = "A lightweight, local focused AI assistant with persistent memory - stripped down OpenClaw in Rust"
license = "Apache-2.0"
repository = "https://github.com/localgpt-app/localgpt"

[dependencies]
# Async runtime
tokio = { version = "1.43", features = ["full"] }

# CLI
clap = { version = "4.5", features = ["derive", "env"] }

# HTTP client for LLM APIs
reqwest = { version = "0.12", features = ["json", "stream"] }

# HTTP server
axum = { version = "0.8", features = ["ws", "macros"] }
tower-http = { version = "0.6", features = ["cors", "trace"] }

# Database
rusqlite = { version = "0.32", features = ["bundled", "functions", "vtab", "load_extension"] }

# Vector search extension for SQLite
sqlite-vec = "0.1.7-alpha.2"

# Local embeddings (default - no API key needed)
fastembed = "5.8"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
json5 = "0.4"
toml = "0.8"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# File watching
notify = "7.0"
notify-debouncer-mini = "0.5"

# Token counting
tiktoken-rs = "0.6"

# Static file embedding for Web UI
rust-embed = { version = "8", features = ["compression"] }
mime_guess = "2.0"

# Utilities
chrono = { version = "0.4", features = ["serde"] }
directories = "6.0"
thiserror = "2.0"
anyhow = "1.0"
uuid = { version = "1.11", features = ["v4"] }
async-trait = "0.1"
futures = "0.3"
tokio-stream = "0.1"
async-stream = "0.3"
shellexpand = "3.1"
glob = "0.3"
base64 = "0.22"

# Unix daemonization (optional, only for daemon mode)
[target.'cfg(unix)'.dependencies]
daemonize = "0.5"
sha2 = "0.10"
rustyline = "17.0.2"

[dev-dependencies]
tempfile = "3.14"
mockall = "0.13"

[[bin]]
name = "localgpt"
path = "src/main.rs"

[profile.release]
lto = true
codegen-units = 1
strip = true
